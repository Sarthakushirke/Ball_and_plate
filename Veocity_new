# import the necessary packages
import socket
from collections import deque
import numpy as np
import argparse
import imutils
import cv2
import time
from scipy.signal import savgol_filter

serverAddressPort=("192.168.141.7", 49001)
bufferSize=32

#create UDP socket
UDPClientSocket=socket.socket(family=socket.AF_INET, type=socket.SOCK_DGRAM)

# construct the argument parse and parse the arguments
ap = argparse.ArgumentParser()
ap.add_argument("-v", "--video",
                help="path to the (optional) video file")
ap.add_argument("-b", "--buffer", type=int, default=64,
                help="max buffer size")
args = vars(ap.parse_args())

# define the lower and upper boundaries of the "yellow object"
# (or "ball") in the HSV color space, then initialize the
# list of tracked points
# colorLower = (10, 100, 20)
# colorUpper = (25, 255, 255)

colorLower = (0, 0, 0)
colorUpper = (179, 255, 30)

pts = deque(maxlen=args["buffer"])

# if a video path was not supplied, grab the reference
# to the webcam
if not args.get("video", False):
    camera = cv2.VideoCapture(0)

# otherwise, grab a reference to the video file
else:
    camera = cv2.VideoCapture(args["video"])

start_time = time.time()
prev_center = None
prev_velocity_x = None
prev_velocity_y = None
velocity_x = 0
velocity_y = 0

# keep looping
while True:
    # grab the current frame
    (grabbed, frame) = camera.read()

    # Calculate frame rate
    elapsed_time = 0.01    #time.time() - start_time

    # if we are viewing a video and we did not grab a frame,
    # then we have reached the end of the video
    if args.get("video") and not grabbed:
        break

    # resize the frame, inverted ("vertical flip" w/ 180degrees),
    # blur it, and convert it to the HSV color space
    frame = imutils.resize(frame, width=600)
    # Print the shape of the resized frame
    #print("Image size: {} x {}".format(frame.shape[1], frame.shape[0]))
    #frame = imutils.rotate(frame, angle=180)
    # blurred = cv2.GaussianBlur(frame, (11, 11), 0)
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

    # construct a mask for the color "green", then perform
    # a series of dilations and erosions to remove any small
    # blobs left in the mask
    mask = cv2.inRange(hsv, colorLower, colorUpper)
    mask = cv2.erode(mask, None, iterations=2)
    mask = cv2.dilate(mask, None, iterations=2)

    # find contours in the mask and initialize the current
    # (x, y) center of the ball
    cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,
                            cv2.CHAIN_APPROX_SIMPLE)[-2]
    center = None

    # only proceed if at least one contour was found
    if len(cnts) > 0:
        # find the largest contour in the mask, then use
        # it to compute the minimum enclosing circle and
        # centroid
        c = max(cnts, key=cv2.contourArea)
        ((x, y), radius) = cv2.minEnclosingCircle(c)
        M = cv2.moments(c)
        center = (int(M["m10"] / M["m00"]), int(M["m01"] / M["m00"]))
        #print(x,y)
        # only proceed if the radius meets a minimum size
        if radius > 10:
            # draw the circle and centroid on the frame,
            # then update the list of tracked points
            cv2.circle(frame, (int(x), int(y)), int(radius),
                       (0, 255, 255), 2)
            cv2.circle(frame, center, 5, (0, 0, 255), -1)
            # print the center coordinates
            print("Center pixels: ({}, {})".format(center[0], center[1]))
            # Convert center coordinates to bytes
            center_x_1 = center[0]%256
            center_x_2 = center[0] // 256
            center_y_1 = center[1]%256
            center_y_2 = center[1] // 256
            #print("Center bits: ({}, {})".format(center_x_1, center_y))
            #send ball position to MicrolabBox
            bytesToSend = bytearray([center_x_1,center_x_2, 0, 0,center_y_1, center_y_2])
            # To convert back to pixels:
            convert_px_x = center_x_1 + center_x_2 * 256
            convert_px_y = center_y_1 + center_y_2 * 256
            #print("Again in pixels: ({}, {})".format(convert_px_x, convert_px_y))

            # Calculate velocity if we have a previous center
            if prev_center is not None:
                prev_x, prev_y = prev_center
                curr_x, curr_y = center
                #distance = np.sqrt((curr_x - prev_x) ** 2 + (curr_y - prev_y) ** 2)
                distance_x = curr_x - prev_x
                distance_y = curr_y - prev_y
                velocity_x = distance_x / elapsed_time
                velocity_y = distance_y / elapsed_time
                print("Velocity: ({:.2f},{:.2f}) pixels per second".format(velocity_x,velocity_y))

                # # Apply Savitzky-Golay filter to the velocity
                if prev_velocity_x is not None:
                    #For filtered velocity x
                    velocity_x = np.array([prev_velocity_x, velocity_x])
                    filtered_velocity_x = savgol_filter(velocity_x, window_length=2, polyorder=1, deriv=1)[-1]
                    print("Filtered Velocity: {:.2f} pixels per second".format(filtered_velocity_x))
                    prev_velocity_x = filtered_velocity_x
                    #For filtered velocity y
                    velocity_x = np.array([prev_velocity_y, velocity_y])
                    filtered_velocity_y = savgol_filter(velocity_y, window_length=2, polyorder=1, deriv=1)[-1]
                    print("Filtered Velocity: {:.2f} pixels per second".format(filtered_velocity_x))
                    prev_velocity_y = filtered_velocity_y
                    
                    

            else:
                # If prev_velocity is None, assign the initial velocity without filtering
                print("Initial Velocity: ({:.2f},{:.2f}) pixels per second".format(velocity_x,velocity_y))
                prev_velocity_x = velocity_x
                prev_velocity_y = velocity_y

            # Update previous center
            prev_center = center
            # print("previous center: {}".format(prev_center))

            # Send the bytes over UDP
            UDPClientSocket.sendto(bytesToSend, serverAddressPort)

    # update the points queue
    pts.appendleft(center)

    # loop over the set of tracked points
    for i in range(1, len(pts)):
        # if either of the tracked points are None, ignore
        # them
        if pts[i - 1] is None or pts[i] is None:
            continue

        # otherwise, compute the thickness of the line and
        # draw the connecting lines
        thickness = int(np.sqrt(args["buffer"] / float(i + 1)) * 2.5)
        cv2.line(frame, pts[i - 1], pts[i], (0, 0, 255), thickness)

    # show the frame to our screen
    cv2.imshow("Frame", frame)
    key = cv2.waitKey(1) & 0xFF



    # if the 'q' key is pressed, stop the loop
    if key == ord("q"):
        break

# cleanup the camera and close any open windows
camera.release()
cv2.destroyAllWindows()

